import numpy as np
import torch
from utils import check_collisions,check_collisions_obstance,getDatasetPersonInfo

def social_force_update(locations, velocities, target_locations,obstacle=None,tau=0.5, time_step=0.4 ,
                        lambda_1=0.35,lambda_2=0.4, sensing=3, lambda_3=0.15,lambda_4=0.45,
                        desired_speed=1.3,angle_threshold=0.8333*3.1415926):
    """
    SFM
    Args:
    locations (torch.Tensor):å½¢çŠ¶ä¸º [n, 2] çš„å¼ é‡ï¼Œè¡¨ç¤ºä»£ç†çš„å½“å‰ä½ç½®ï¼ˆç±³ï¼‰.
    velocities (torch.Tensor): å½¢çŠ¶ä¸º [n, 2] çš„å¼ é‡ï¼Œè¡¨ç¤ºä»£ç†çš„å½“å‰é€Ÿåº¦ (m/s).
    target_locations (torch.Tensor): å½¢çŠ¶ä¸º [n, 2] çš„å¼ é‡ï¼Œè¡¨ç¤ºä»£ç†çš„ç›®æ ‡ä½ç½®ï¼ˆç±³ï¼‰.
    obstacle:å½¢çŠ¶ä¸º [m, 2] çš„å¼ é‡ï¼Œè¡¨ç¤ºä¸ºéšœç¢ç‰©çš„ä½ç½®(è§„åˆ’ä¸ºåœ†)
    time_step (float, optional): æ›´æ–°ä½ç½®å’Œé€Ÿåº¦çš„æ—¶é—´æ­¥é•¿ï¼ˆç§’ï¼‰ã€‚ é»˜è®¤å€¼ä¸º 0.4.
    tau:ğœç›®æ ‡å¸å¼•åŠ›ç³»æ•°
    lambda_1 (float, optional): ä»£ç†ä¹‹é—´çš„æ’æ–¥åŠ›å¼ºåº¦ï¼ˆç‰›é¡¿ï¼‰ã€‚ é»˜è®¤å€¼ä¸º 200.0.
    lambda_2 (float, optional): æ„Ÿå—åˆ°æ’æ–¥åŠ›çš„è°ƒæ•´å‚æ•°ã€‚ é»˜è®¤å€¼ä¸º 0.08.
    sensing (float, optional): æ„Ÿå—åˆ°æ’æ–¥åŠ›çš„è·ç¦»ï¼ˆç±³ï¼‰ã€‚ é»˜è®¤å€¼ä¸º 3.
    lambda_ (float, optional): æ§åˆ¶æ™ºèƒ½ä½“å›é¿åŠ›çš„è°ƒæ•´å‚æ•°ã€‚ é»˜è®¤å€¼ä¸º 0.35.

    desired_speed (float, optional): ä»£ç†çš„æ‰€éœ€é€Ÿåº¦ï¼ˆç±³/ç§’ï¼‰ã€‚ é»˜è®¤å€¼ä¸º 1.3.
    angle_threshold:è§†é‡è§’
    Returns:
    updated_locations (torch.Tensor): å½¢çŠ¶ä¸º [n, 2] çš„å¼ é‡ï¼Œè¡¨ç¤ºä»£ç†çš„æ›´æ–°ä½ç½®ï¼ˆç±³ï¼‰.
    updated_velocities (torch.Tensor): å½¢çŠ¶ä¸º [n, 2] çš„å¼ é‡ï¼Œè¡¨ç¤ºä»£ç†çš„æ›´æ–°é€Ÿåº¦ (m/s).
    """

    # Get the number of agents

    #ä¸€ã€ç›®æ ‡å¸å¼•åŠ›è®¡ç®—#######
    #1.è®¡ç®—æœå‘
    desired_directions = (target_locations - locations) / (torch.norm(target_locations - locations, dim=-1, keepdim=True) + 1e-9) #ç›®æ ‡æ–¹å‘
    #2. è®¡ç®—æœŸæœ›é€Ÿåº¦
    desired_velocities = desired_speed * desired_directions #æœŸæœ›é€Ÿåº¦
    #3.è®¡ç®—é€Ÿåº¦å·®å¼‚
    dv = desired_velocities - velocities #æœŸæœ›é€Ÿåº¦ä¸å®é™…é€Ÿåº¦çš„å·®å¼‚
    #4.ç¼©æ”¾
    dv=dv/tau
    #####################


    #äºŒã€è®¡ç®—Agenté—´åŠ›#################################
    social_force_agent = torch.zeros_like(locations)
    n = locations.size(0)
    # è®¡ç®—ç¢°æ’æƒ…å†µ
    for i in range(n):
        for j in range(n):
            if i != j:
                # 1.è®¡ç®—è·ç¦»
                diff_loc = locations[i] - locations[j]
                distance = torch.norm(diff_loc)
                if distance <= sensing:
                    # 2.å½’ä¸€åŒ–(æ–¹å‘)
                    normalized_diff_loc = diff_loc / (distance + 1e-9) #æœå‘
                    dot_product = torch.dot(velocities[i], normalized_diff_loc)
                    cosine_similarity = dot_product / (torch.norm(velocities[i]) * torch.norm(normalized_diff_loc))
                    angle_between = torch.acos(torch.clamp(cosine_similarity, -1.0, 1.0))
                    # æ£€æŸ¥å¤¹è§’æ˜¯å¦åœ¨é™åˆ¶èŒƒå›´å†…
                    if angle_between <= angle_threshold / 2:
                        # 3.è®¡ç®—ç¤¾ä¼šåŠ›
                        social_force_ij = lambda_1 * torch.exp(-distance / lambda_2) * normalized_diff_loc
                        # 4.æ±‚å’Œ
                        social_force_agent[i] += social_force_ij
    ################################################

    # ä¸‰ã€è®¡ç®—éšœç¢ç‰©åŠ›#################################
    social_force_obstance = torch.zeros_like(locations)
    n = locations.size(0)
    m = 0
    if obstacle is not None:
        m = obstacle.size(0)
    for i in range(n):
        for j in range(m):
            # 1.è®¡ç®—è·ç¦»
            diff_loc = locations[i] - obstacle[j]
            distance = torch.norm(diff_loc)
            if distance <= sensing:
                # 2.å½’ä¸€åŒ–(æ–¹å‘)
                normalized_diff_loc = diff_loc / (distance + 1e-9)
                dot_product = torch.dot(velocities[i], normalized_diff_loc)
                cosine_similarity = dot_product / (torch.norm(velocities[i]) * torch.norm(normalized_diff_loc))
                angle_between = torch.acos(torch.clamp(cosine_similarity, -1.0, 1.0))
                # æ£€æŸ¥å¤¹è§’æ˜¯å¦åœ¨é™åˆ¶èŒƒå›´å†…
                if angle_between <= angle_threshold / 2:
                    # 3.è®¡ç®—ç¤¾ä¼šåŠ›
                    social_force_ij = lambda_3 * torch.exp(-distance / lambda_4) * normalized_diff_loc
                    # 4.æ±‚å’Œ
                    social_force_obstance[i] += social_force_ij
    ################################################
    force = (dv + social_force_agent+social_force_obstance)

    lengths = torch.sqrt(torch.sum(force ** 2, dim=1))
    mask = lengths > 1.5
    # ç¼©æ”¾è¿™äº›å‘é‡
    force[mask] = force[mask] / lengths[mask].unsqueeze(1) * 1.5  # é˜²æ­¢Qå¼¹ï¼Œç¼©æ”¾å‘é‡
    # Update the velocities by adding the difference in velocities and social force, scaled by the time step
    updated_velocities = velocities + time_step * force

    # Update the locations by adding the updated velocities, scaled by the time step
    updated_locations = locations + time_step * updated_velocities

    return updated_locations, updated_velocities



def R_update(locations, velocities, target_locations,obstacle=None,tau=1, time_step=0.4 ,
             lambda_1=100.0,lambda_2=0.15, sensing=3, lambda_3=100.0,lambda_4=0.08, desired_speed=1.3,angle_threshold=0.8333*3.1415926):
    """
    SFM
    Args:
    locations (torch.Tensor):å½¢çŠ¶ä¸º [n, 2] çš„å¼ é‡ï¼Œè¡¨ç¤ºä»£ç†çš„å½“å‰ä½ç½®ï¼ˆç±³ï¼‰.
    velocities (torch.Tensor): å½¢çŠ¶ä¸º [n, 2] çš„å¼ é‡ï¼Œè¡¨ç¤ºä»£ç†çš„å½“å‰é€Ÿåº¦ (m/s).
    target_locations (torch.Tensor): å½¢çŠ¶ä¸º [n, 2] çš„å¼ é‡ï¼Œè¡¨ç¤ºä»£ç†çš„ç›®æ ‡ä½ç½®ï¼ˆç±³ï¼‰.
    obstacle:å½¢çŠ¶ä¸º [m, 2] çš„å¼ é‡ï¼Œè¡¨ç¤ºä¸ºéšœç¢ç‰©çš„ä½ç½®(è§„åˆ’ä¸ºåœ†)
    time_step (float, optional): æ›´æ–°ä½ç½®å’Œé€Ÿåº¦çš„æ—¶é—´æ­¥é•¿ï¼ˆç§’ï¼‰ã€‚ é»˜è®¤å€¼ä¸º 0.4.
    tau:ğœç›®æ ‡å¸å¼•åŠ›ç³»æ•°
    lambda_1 (float, optional): ä»£ç†ä¹‹é—´çš„æ’æ–¥åŠ›å¼ºåº¦ï¼ˆç‰›é¡¿ï¼‰ã€‚ é»˜è®¤å€¼ä¸º 200.0.
    lambda_2 (float, optional): æ„Ÿå—åˆ°æ’æ–¥åŠ›çš„è°ƒæ•´å‚æ•°ã€‚ é»˜è®¤å€¼ä¸º 0.08.
    sensing (float, optional): æ„Ÿå—åˆ°æ’æ–¥åŠ›çš„è·ç¦»ï¼ˆç±³ï¼‰ã€‚ é»˜è®¤å€¼ä¸º 3.
    lambda_ (float, optional): æ§åˆ¶æ™ºèƒ½ä½“å›é¿åŠ›çš„è°ƒæ•´å‚æ•°ã€‚ é»˜è®¤å€¼ä¸º 0.35.

    desired_speed (float, optional): ä»£ç†çš„æ‰€éœ€é€Ÿåº¦ï¼ˆç±³/ç§’ï¼‰ã€‚ é»˜è®¤å€¼ä¸º 1.3.
    angle_threshold:è§†é‡è§’
    Returns:
    updated_locations (torch.Tensor): å½¢çŠ¶ä¸º [n, 2] çš„å¼ é‡ï¼Œè¡¨ç¤ºä»£ç†çš„æ›´æ–°ä½ç½®ï¼ˆç±³ï¼‰.
    updated_velocities (torch.Tensor): å½¢çŠ¶ä¸º [n, 2] çš„å¼ é‡ï¼Œè¡¨ç¤ºä»£ç†çš„æ›´æ–°é€Ÿåº¦ (m/s).
    """

    # Get the number of agents

    #ä¸€ã€ç›®æ ‡å¸å¼•åŠ›è®¡ç®—#######
    #1.è®¡ç®—æœå‘
    desired_directions = (target_locations - locations) / (torch.norm(target_locations - locations, dim=-1, keepdim=True) + 1e-9) #ç›®æ ‡æ–¹å‘
    #2. è®¡ç®—æœŸæœ›é€Ÿåº¦
    desired_velocities = desired_speed * desired_directions #æœŸæœ›é€Ÿåº¦
    #3.è®¡ç®—é€Ÿåº¦å·®å¼‚
    dv = desired_velocities - velocities #æœŸæœ›é€Ÿåº¦ä¸å®é™…é€Ÿåº¦çš„å·®å¼‚
    #4.ç¼©æ”¾
    dv=dv/tau
    #####################

    col_agent=check_collisions(locations)
    check_collisions_obstance(locations,obstacle)

    # ä¸‰ã€è®¡ç®—éšœç¢ç‰©åŠ›#################################
    social_force_obstance = torch.zeros_like(locations)
    n = locations.size(0)
    m = 0
    if obstacle is not None:
        m = obstacle.size(0)
    for i in range(n):
        for j in range(m):
            if i != j:
                # 1.è®¡ç®—è·ç¦»
                diff_loc = locations[i] - obstacle[j]
                distance = torch.norm(diff_loc)
                if distance <= sensing:
                    # 2.å½’ä¸€åŒ–(æ–¹å‘)
                    normalized_diff_loc = diff_loc / (distance + 1e-9)
                    dot_product = torch.dot(velocities[i], normalized_diff_loc)
                    cosine_similarity = dot_product / (torch.norm(velocities[i]) * torch.norm(normalized_diff_loc))
                    angle_between = torch.acos(torch.clamp(cosine_similarity, -1.0, 1.0))
                    # æ£€æŸ¥å¤¹è§’æ˜¯å¦åœ¨é™åˆ¶èŒƒå›´å†…
                    if angle_between <= angle_threshold / 2:
                        # 3.è®¡ç®—ç¤¾ä¼šåŠ›æˆ–R_i
                        if col_agent[i]==True or check_collisions_obstance==True:
                            social_force_ij = diff_loc*(0.3+0.1-distance)/distance
                        else:
                            social_force_ij = lambda_3 * torch.exp(-distance / lambda_4) * normalized_diff_loc
                        # 4.æ±‚å’Œ
                        social_force_obstance[i] += social_force_ij
    ################################################

    #äºŒã€è®¡ç®—Agenté—´åŠ›#################################
    social_force_agent = torch.zeros_like(locations)
    n = locations.size(0)
    # è®¡ç®—ç¢°æ’æƒ…å†µ
    for i in range(n):
        for j in range(n):
            if i != j:
                # 1.è®¡ç®—è·ç¦»
                diff_loc = locations[i] - locations[j]
                distance = torch.norm(diff_loc)
                if distance <= sensing:
                    # 2.å½’ä¸€åŒ–(æ–¹å‘)
                    normalized_diff_loc = diff_loc / (distance + 1e-9)
                    dot_product = torch.dot(velocities[i], normalized_diff_loc)
                    cosine_similarity = dot_product / (torch.norm(velocities[i]) * torch.norm(normalized_diff_loc))
                    angle_between = torch.acos(torch.clamp(cosine_similarity, -1.0, 1.0))
                    # æ£€æŸ¥å¤¹è§’æ˜¯å¦åœ¨é™åˆ¶èŒƒå›´å†…
                    if angle_between <= angle_threshold / 2:
                        # 3.è®¡ç®—ç¤¾ä¼šåŠ›æˆ–R_i
                        if col_agent[i] == True or check_collisions_obstance == True:
                            social_force_ij = diff_loc * (0.4 + 0.2 - distance) / distance
                        else:
                            social_force_ij = lambda_1 * torch.exp(-distance / lambda_2) * normalized_diff_loc
                        # 4.æ±‚å’Œ
                        social_force_agent[i] += social_force_ij
    ################################################

    # å¦‚æœæœ‰R_obstacle åˆ™R_iè®¾ç½®ç¼©æ”¾ä¸º0.3
    # å¦‚æœå‘ç”Ÿç¢°æ’ä¸ç”¨å¸å¼•åŠ›
    for i in range(locations.size(0)):
        if col_agent[i] == True or check_collisions_obstance == True:
            dv[i] = torch.tensor(0)
            if torch.norm(social_force_obstance[i])!=0:
                social_force_agent[i]*=0.3

    force=dv + social_force_agent+social_force_obstance

    lengths = torch.sqrt(torch.sum(force**2, dim=1))
    mask = lengths > 1.5
    # ç¼©æ”¾è¿™äº›å‘é‡
    force[mask] = force[mask] / lengths[mask].unsqueeze(1) * 1.5#é˜²æ­¢Qå¼¹ï¼Œç¼©æ”¾å‘é‡
    # Update the velocities by adding the difference in velocities and social force, scaled by the time step
    updated_velocities = velocities + time_step * force

    # Update the locations by adding the updated velocities, scaled by the time step
    updated_locations = locations + time_step * updated_velocities

    return updated_locations, updated_velocities

def find_agent_collision(people_positions, sensing=0.4):
    n, len, _ = people_positions.shape
    # å°†äººçš„ä½ç½®è¿›è¡Œå¹¿æ’­
    position_data_expanded = people_positions.unsqueeze(1).expand(n, n, len, 2)
    vector = people_positions.unsqueeze(0) - position_data_expanded
    distances = torch.norm(vector, dim=3)
    # åˆ›å»ºä¸€ä¸ªå¸ƒå°”æ©ç ï¼ŒæŒ‡ç¤ºè·ç¦»å°äº0.4ç±³çš„æƒ…å†µ
    mask = (distances < sensing)
    index = mask.nonzero(as_tuple=False)
    # è¿‡æ»¤æ‰ç¬¬0ä½å’Œç¬¬1ä½ç›¸åŒçš„ç´¢å¼•
    index = index[index[:, 0] != index[:, 1]]
    return index,vector,distances  # ç´¢å¼•,å…¨éƒ¨å·®å€¼,è·ç¦»
def find_obstacles_collision(people_positions,  obstacle_positions,sensing=0.5):
    n, len, _ = people_positions.shape
    num_obstacles, _ = obstacle_positions.shape
    # å°†äººçš„ä½ç½®å’Œéšœç¢ç‰©ä½ç½®æ‰©å±•ä¸ºç›¸åŒå½¢çŠ¶ä»¥è¿›è¡Œå¹¿æ’­
    people_positions_expanded = people_positions.unsqueeze(2).expand(n, len, num_obstacles, 2)
    # è®¡ç®—äººå’Œéšœç¢ç‰©ä¹‹é—´çš„è·ç¦»
    vector = obstacle_positions-people_positions_expanded
    distances = torch.norm(vector, dim=3)
    # åˆ›å»ºä¸€ä¸ªå¸ƒå°”æ©ç ï¼ŒæŒ‡ç¤ºè·ç¦»å°äº2ç±³çš„æƒ…å†µ
    mask = (distances <= sensing)
    # è¿”å›è·ç¦»å°äº2ç±³çš„éšœç¢ç‰©çš„ç´¢å¼•
    index = mask.nonzero(as_tuple=False)
    return index,vector,distances #ç´¢å¼•,å…¨éƒ¨å·®å€¼,è·ç¦»
def R_force(locations,obstacle,seq_start_end,lambda_a=0.3):
    r_force_c=torch.zeros_like(locations)
    for se in seq_start_end:
        indexs,vector,distances=find_agent_collision(locations[se[0]:se[1]])
        if indexs.size(0)>0:
            force_c= -vector*(0.4 + 0.2 - distances.unsqueeze(-1)) / distances.unsqueeze(-1)
            nan_mask = torch.isnan(force_c)
            force_c[nan_mask] = 0
            agent_len_index=indexs[:,[0,2]] #Agentåœ¨å“ªä¸ªä½ç½®å‘ç”Ÿç¢°æ’çš„ç´¢å¼•
            agent_len_index=torch.unique(agent_len_index, dim=0)
            for index in agent_len_index:
                mask=indexs[(indexs[:,0]==index[0])&(indexs[:,2]==index[1])]
                agent_force_c=force_c[mask[:, 0], mask[:, 1], mask[:, 2]]
                r_force_c[index[0]][index[1]]=agent_force_c.mean(dim=0)


    r_force_o = torch.zeros_like(locations)
    for i,se in enumerate(seq_start_end):
        indexs, vector, distances = find_obstacles_collision(locations[se[0]:se[1]],obstacle[i])
        if indexs.size(0) > 0:
            force_o = -vector * (0.3 + 0.3 - distances.unsqueeze(-1)) / distances.unsqueeze(-1)
            nan_mask = torch.isnan(force_o)
            force_o[nan_mask] = 0
            agent_len_index=indexs[:,[0,1]] #Agentåœ¨å“ªä¸ªä½ç½®å‘ç”Ÿç¢°æ’çš„ç´¢å¼•
            agent_len_index=torch.unique(agent_len_index, dim=0)
            for index in agent_len_index:
                mask = indexs[(indexs[:, 0] == index[0]) & (indexs[:, 1] == index[1])]
                agent_force_o = force_o[mask[:, 0], mask[:, 1], mask[:, 2]]
                r_force_o[index[0]][index[1]] = agent_force_o.mean(dim=0)
    o_mask=torch.norm(r_force_o,dim=-1)>0
    r_force_c[o_mask]*=lambda_a
    r=(r_force_c+r_force_o)
    return r






# ç¤ºä¾‹ä»£ç ä¿æŒä¸å˜

def get_collision_times(locations, collision_threshold=0.4):
    n = locations.size(0)
    collision_times = 0
    for i in range(n):
        for j in range(i + 1, n):
            if (torch.norm(locations[i] - locations[j]) < collision_threshold):
                collision_times += 1
    return collision_times


def social_force_collision(dsname,dspeed=2.2):
    # æ•°æ®é›†æ—¶é—´æ­¥é•¿ä¸º0.4
    time_step = 0.4
    dataset_collision_times = []
    dataset_sfm_trajs = []
    datainfo = getDatasetPersonInfo(dsname)
    # print(len(datainfo))
    for info in datainfo:
        # region DATA VISULIZATION
        # Create the figure
        # fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))
        # plt.ion()
        # endregion

        # idï¼Œå¼€å§‹å¸§ï¼Œç»“æŸå¸§ï¼Œå¼€å§‹ä½ç½®ï¼Œç›®æ ‡ä½
        id, start, end, init, dest,pos = info
        # print(init)

        # idå’Œè½¨è¿¹çš„é”®å€¼å¯¹
        traj_dict = {}
        # idå’Œé€Ÿåº¦çš„é”®å€¼å¯¹
        velocities_dict = {}
        for i in range(len(id)):
            traj_dict[id[i]] = init[i]
            velocities_dict[id[i]] = (init[i][1] - init[i][0]) / time_step
        # print(velocities_dict)

        # åˆå§‹åŒ–ç¢°æ’æ¬¡æ•°ä¸º0
        collision_times = 0
        # ä»¥infoä¸­æœ€å°çš„å¼€å§‹å¸§åˆå§‹åŒ–å½“å‰å¸§
        first_frame = min(start)
        cur_frame = first_frame
        # infoä¸­çš„æœ€å¤§å¸§
        last_frame = max(end)
        # å½“å‰å¸§å°äºæœ€å¤§å¸§æ—¶ï¼Œè¿›è¡Œè®¡ç®—
        while cur_frame < last_frame - 1:
            cur_frame += 1
            curt_ids = []  # å½“å‰å¸§å­˜åœ¨ä¸ªä½“çš„çš„ID
            cur_trajs = []  # å½“å‰å¸§å­˜åœ¨çš„ä¸ªä½“çš„è½¨è¿¹
            cur_velocities = []  # å½“å‰å¸§å­˜åœ¨ä¸ªä½“çš„é€Ÿåº¦
            cur_targets = []  # å½“å‰å¸§å­˜åœ¨ä¸ªä½“çš„ç›®æ ‡

            # éå†æ¯ä¸ªäººï¼Œå°†å½“å‰å¸§éœ€è¦æ›´æ–°äººçš„ç´¢å¼•ã€è½¨è¿¹ã€ç›®æ ‡å­˜å‚¨åˆ°æ•°ç»„ä¸­
            for i in range(len(id)):
                if start[i] < cur_frame and end[i] > cur_frame:  # åˆ¤æ–­agentåœ¨å½“å‰å¸§æ˜¯å¦å­˜åœ¨
                    curt_ids.append(id[i])  # id
                    cur_trajs.append(traj_dict[id[i]])  # è½¨è¿¹
                    cur_velocities.append(velocities_dict[id[i]])  # é€Ÿåº¦
                    cur_targets.append(dest[i])  # ç›®æ ‡
            if len(curt_ids) == 0:
                continue

            # è·å–å½“å‰å¸§æ‰€æœ‰ä¸ªä½“çš„ä½ç½®
            locations = [cur_trajs[i][-1] for i in range(len(cur_trajs))]
            locations = np.stack(locations, axis=0)
            locations = torch.from_numpy(locations).to(dtype=torch.float32)
            # print("location: " + str(locations.shape))

            # region DATA VISULIZATION
            # Draw the updated frame
            # ax1.cla()
            # ax1.scatter(locations[:,0], locations[:,1], c='r', marker='o', label='SFM')
            # ax1.set_title('SFM'+str(locations.shape[0]))
            # ax1.set_xlabel('X-axis')
            # ax1.set_ylabel('Y-axis')
            # ax1.legend()

            # ax2.cla()
            # ax2.scatter(locations[:,0], locations[:,1], c='b', marker='o', label='Real Data')
            # ax2.set_title('Sample Data'+str(locations.shape[0]))
            # ax2.set_xlabel('X-axis')
            # ax2.set_ylabel('Y-axis')
            # ax2.legend()
            # endregion

            # è·å–å½“å‰å¸§æ‰€æœ‰ä¸ªä½“çš„é€Ÿåº¦
            # velocities = [(cur_trajs[i][-1]-cur_trajs[i][-2])/time_step for i in range(len(cur_trajs))]
            velocities = np.stack(cur_velocities, axis=0)
            velocities = torch.from_numpy(velocities).to(dtype=torch.float32)
            # print("Velocity: " + str(velocities.shape))

            # è·å–å½“å‰å¸§æ‰€æœ‰ä¸ªä½“çš„ç›®æ ‡ä½ç½®
            target_locations = np.stack(cur_targets, axis=0)
            target_locations = torch.from_numpy(target_locations).to(dtype=torch.float32)
            # print("target_locations: " + str(target_locations.shape))

            # æ ¹æ®å½“å‰å¸§ä½ç½®è®¡ç®—ç¢°æ’æ¬¡æ•°
            collision_times += get_collision_times(locations, collision_threshold=0.4)

            # æ ¹æ®sfmè®¡ç®—ä¸‹ä¸€å¸§ä½ç½®ï¼Œä¸ºäº†sfmçš„æ•ˆæœï¼Œé€šè¿‡sfm_multi_timesæ§åˆ¶æ¯timestepä¹‹é—´sfmçš„è¿­ä»£æ¬¡æ•°
            sfm_multi_times = 5
            for _ in range(sfm_multi_times):
                locations, velocities = social_force_update(locations, velocities, target_locations,
                                                            time_step=time_step / sfm_multi_times,desired_speed=dspeed)
                # region DATA VISULIZATION
                # ax1.cla()
                # ax1.scatter(locations[:,0], locations[:,1], c='r', marker='o', label='SFM')
                # ax1.set_title('SFM'+str(locations.shape[0]))
                # ax1.set_xlabel('X-axis')
                # ax1.set_ylabel('Y-axis')
                # ax1.legend()
                # plt.pause(time_step/sfm_multi_times)
                # endregion

            # å¦‚æœæ˜¯æœ€åä¸€å¸§ï¼Œå†å•ç‹¬è®¡ç®—ä¸€æ¬¡ç¢°æ’æ¬¡æ•°
            if (cur_frame == last_frame):
                collision_times += get_collision_times(locations, collision_threshold=0.4)

            # å°†sfmè®¡ç®—å¾—å‡ºçš„ä½ç½®å­˜å…¥è½¨è¿¹dictä¸­
            for i, cur_id in enumerate(curt_ids):
                traj_dict[cur_id] = np.concatenate([traj_dict[cur_id], locations[i].unsqueeze(0).numpy()], axis=0)
                velocities_dict[cur_id] = velocities[i].numpy()
                # print("dict shape: " + str(dict[cur_id].shape))
                # print("loc shape: " + str(locations[i].unsqueeze(0).numpy().shape))

        # region DATA VISULIZATION
        # plt.ioff()
        # plt.show()
        # endregion

        print(collision_times)
        dataset_collision_times.append(collision_times)
        dataset_sfm_trajs.append(list(traj_dict.values()))

    return dataset_collision_times, dataset_sfm_trajs



def deepsfm_update(locations, velocities, target_locations,obstacle,seq_start_end,tau,index_c, lambda_c,index_o, lambda_o,time_step=0.4,desired_speed=None):

    # Get the number of agents

    #ä¸€ã€ç›®æ ‡å¸å¼•åŠ›è®¡ç®—#######
    #1.è®¡ç®—æœå‘
    vector=target_locations- locations #ä¸æœ€åä¸€ä¸ªä½ç½®çš„æ–¹å‘å·®å€¼
    desired_directions = vector / (torch.norm(vector, dim=-1, keepdim=True) + 1e-5) #ç›®æ ‡æ–¹å‘


    # 2. è®¡ç®—æœŸæœ›é€Ÿåº¦
    if desired_speed is not None:
        desired_velocities=desired_speed * desired_directions#æœŸæœ›é€Ÿåº¦
    else:
        n, length, _ = vector.shape
        scaling_factors = torch.arange(length, 0, -1).cuda() * 0.4
        scaling_factors = scaling_factors.view(1, length, 1)  # Reshape for broadcasting
        # Perform the operation
        desired_velocities = vector / scaling_factors


    #3.è®¡ç®—é€Ÿåº¦å·®å¼‚
    dv = desired_velocities - velocities#æœŸæœ›é€Ÿåº¦ä¸å®é™…é€Ÿåº¦çš„å·®å¼‚
    #4.ç¼©æ”¾
    dv=dv/(tau+0.4) #0.4ä¸ºæ—¶é—´å¸¸æ•°
    #####################


    #äºŒã€è®¡ç®—Agenté—´åŠ›#################################
    social_force_agent = torch.zeros_like(locations)
    # è®¡ç®—ç¢°æ’æƒ…å†µ
    num=0
    for i,se in enumerate(seq_start_end):
        n=se[1]-se[0]
        len=locations.size(1)
        traj_group=locations[se[0]:se[1]]
        position_data_expanded = traj_group.unsqueeze(1).expand(n, n, len, 2)
        vector = traj_group.unsqueeze(0) - position_data_expanded #iåˆ°j (j-i)
        distances = torch.norm(vector,dim=-1)
        directions = vector / (distances.unsqueeze(3) + 1e-5)
        social_force_ij = torch.clamp(lambda_c[i][:,:,:,0:1],min=0.1) * torch.exp(-distances.unsqueeze(-1) / (lambda_c[i][:,:,:,1:])) * (-directions)
        for index in index_c[i]:
            num_i,num_j,num_len=index[0],index[1],index[2]
            social_force_agent[num+num_i][num_len] += social_force_ij[num_i][num_j][num_len]
        num+=n
    ################################################

    # ä¸‰ã€è®¡ç®—éšœç¢ç‰©åŠ›#################################
    social_force_obstance = torch.zeros_like(locations)
    num=0
    for i,se in enumerate(seq_start_end):
        n = se[1] - se[0]
        len = locations.size(1)
        traj_group = locations[se[0]:se[1]]
        obstacle_group=obstacle[i]
        num_obstacles, _ = obstacle_group.shape
        # å°†äººçš„ä½ç½®å’Œéšœç¢ç‰©ä½ç½®æ‰©å±•ä¸ºç›¸åŒå½¢çŠ¶ä»¥è¿›è¡Œå¹¿æ’­
        people_positions_expanded = traj_group.unsqueeze(2).expand(n, len, num_obstacles, 2)

        # è®¡ç®—äººå’Œéšœç¢ç‰©ä¹‹é—´çš„è·ç¦»

        vector = obstacle_group - people_positions_expanded
        distances = torch.norm(vector, dim=3)
        directions = vector / (distances.unsqueeze(3) + 1e-5)
        social_force_io = torch.clamp(lambda_o[i][:, :, :, 0:1],min=0.1) * torch.exp(-distances.unsqueeze(-1) / (lambda_o[i][:, :, :, 1:])) * (-directions)
        for index in index_o[i]:
            num_i, num_len, num_ob = index[0], index[1], index[2]
            social_force_obstance[num + num_i][num_len] += social_force_io[num_i][num_len][num_ob]
        num += n
    ################################################

    # Update the velocities by adding the difference in velocities and social force, scaled by the time step
    updated_velocities = velocities + time_step * (dv + social_force_agent+social_force_obstance)

    # Update the locations by adding the updated velocities, scaled by the time step
    updated_locations = locations + time_step * updated_velocities

    return updated_locations

def deepsfm_update_R(locations, velocities, target_locations,obstacle,seq_start_end,tau,index_c, lambda_c,index_o, lambda_o,time_step=0.4,desired_speed=None,col_label=None):

    # Get the number of agents

    # ä¸€ã€ç›®æ ‡å¸å¼•åŠ›è®¡ç®—#######
    # 1.è®¡ç®—æœå‘
    vector = target_locations - locations  # ä¸æœ€åä¸€ä¸ªä½ç½®çš„æ–¹å‘å·®å€¼
    desired_directions = vector / (torch.norm(vector, dim=-1, keepdim=True) + 1e-5)  # ç›®æ ‡æ–¹å‘

    # 2. è®¡ç®—æœŸæœ›é€Ÿåº¦
    if desired_speed is not None:
        desired_velocities = desired_speed * desired_directions  # æœŸæœ›é€Ÿåº¦
    else:
        n, length, _ = vector.shape
        scaling_factors = torch.arange(length, 0, -1).cuda() * 0.4
        scaling_factors = scaling_factors.view(1, length, 1)  # Reshape for broadcasting
        # Perform the operation
        desired_velocities = vector / scaling_factors



    #3.è®¡ç®—é€Ÿåº¦å·®å¼‚
    dv = desired_velocities - velocities#æœŸæœ›é€Ÿåº¦ä¸å®é™…é€Ÿåº¦çš„å·®å¼‚
    #4.ç¼©æ”¾
    dv=dv/(tau+0.4) #0.4ä¸ºæ—¶é—´å¸¸æ•°
    #####################


    #äºŒã€è®¡ç®—Agenté—´åŠ›#################################
    social_force_agent = torch.zeros_like(locations)
    # è®¡ç®—ç¢°æ’æƒ…å†µ
    num=0
    for i,se in enumerate(seq_start_end):
        n=se[1]-se[0]
        len=locations.size(1)
        traj_group=locations[se[0]:se[1]]
        position_data_expanded = traj_group.unsqueeze(1).expand(n, n, len, 2)
        vector = traj_group.unsqueeze(0) - position_data_expanded #iåˆ°j (j-i)
        distances = torch.norm(vector,dim=-1)
        directions = vector / (distances.unsqueeze(3) + 1e-5)
        social_force_ij = torch.clamp(lambda_c[i][:,:,:,0:1],min=0.1) * torch.exp(-distances.unsqueeze(-1) / (lambda_c[i][:,:,:,1:])) * (-directions)
        for index in index_c[i]:
            num_i,num_j,num_len=index[0],index[1],index[2]
            social_force_agent[num+num_i][num_len] += social_force_ij[num_i][num_j][num_len]
        num+=n
    ################################################

    # ä¸‰ã€è®¡ç®—éšœç¢ç‰©åŠ›#################################
    social_force_obstance = torch.zeros_like(locations)
    num=0
    for i,se in enumerate(seq_start_end):
        n = se[1] - se[0]
        len = locations.size(1)
        traj_group = locations[se[0]:se[1]]
        obstacle_group=obstacle[i]
        num_obstacles, _ = obstacle_group.shape
        # å°†äººçš„ä½ç½®å’Œéšœç¢ç‰©ä½ç½®æ‰©å±•ä¸ºç›¸åŒå½¢çŠ¶ä»¥è¿›è¡Œå¹¿æ’­
        people_positions_expanded = traj_group.unsqueeze(2).expand(n, len, num_obstacles, 2)

        # è®¡ç®—äººå’Œéšœç¢ç‰©ä¹‹é—´çš„è·ç¦»

        vector = obstacle_group - people_positions_expanded
        distances = torch.norm(vector, dim=3)
        directions = vector / (distances.unsqueeze(3) + 1e-5)
        social_force_io = torch.clamp(lambda_o[i][:, :, :, 0:1],min=0.1) * torch.exp(-distances.unsqueeze(-1) / (lambda_o[i][:, :, :, 1:])) * (-directions)
        for index in index_o[i]:
            num_i, num_len, num_ob = index[0], index[1], index[2]
            social_force_obstance[num + num_i][num_len] += social_force_io[num_i][num_len][num_ob]
        num += n
    ################################################
    R_f=R_force(locations,obstacle,seq_start_end)
    # Update the velocities by adding the difference in velocities and social force, scaled by the time step
    social_force=dv + social_force_agent+social_force_obstance
    mask=torch.norm(R_f,dim=-1)>0

    social_force[mask]=R_f[mask]
    updated_velocities = velocities + time_step * social_force
    #updated_velocities[mask]=0
    # Update the locations by adding the updated velocities, scaled by the time step
    updated_locations = locations + time_step * updated_velocities
    if col_label!=None:#åˆ¤æ–­æ˜¯å¦è¿ç»­ç¢°æ’ä¸¤æ¬¡
        mask_col = torch.norm(R_f, dim=-1) > 0 & col_label == 1
        updated_locations[mask_col]=locations[mask_col]+R_f[mask_col]


    return updated_locations,torch.norm(R_f,dim=-1)==0

def deepsfm_update_R_with_stoporwaitRule(locations, velocities, target_locations,obstacle,seq_start_end,tau,index_c, lambda_c,index_o, lambda_o,time_step=0.4,col_label=None,desired_speed=None):
    'col_label:Agentæ˜¯å¦è¿ç»­ç¢°æ’éšœç¢ç‰©ä¸¤æ¬¡'
    pass

def waiting_condition(agent, locations, obstacles, other_agents):
    # Define a threshold distance for waiting
    wait_distance = 2.0  # example threshold

    # Check distance to a specific point or condition
    # Example: waiting if within a certain area
    wait_area_center = torch.tensor([5, 5])  # example area center
    if torch.norm(locations[agent] - wait_area_center) < wait_distance:
        return True  # Wait if within the wait area

    pass

    return False

if __name__ == "__main__":
    # Example usage
    n = 100
    locations = torch.rand(n, 2)*10
    velocities = torch.rand(n, 2)
    target_locations = torch.rand(n, 2)*100
    print("Target Locations:\n", target_locations)
    list=[]
    for i in range(100):
        locations, velocities = R_update(locations, velocities, target_locations)
        print("Updated Locations:\n", locations)
        #print("Updated Velocities:\n", velocities)
        list.append(locations)
    frames=torch.stack(list)

    collision_times, trajs = social_force_collision("eth", 2.2)
    #collision_times, trajs = social_force_collision("hotel", 2.2)
    #collision_times, trajs = social_force_collision("univ",1.3)
    #collision_times, trajs = social_force_collision("zara1", 1.3)
    #collision_times, trajs = social_force_collision("zara2", 1.3)

    #print(collision_times)

    # traj_all=[]
    # for traj in trajs:
    #     for t in traj:
    #         traj_all.append(t)
    #
    # #print( getAllAvgScoreByTraj('eth',traj_all))
    # OutCsv(traj_all,'zara2_sfm')
